{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUC60vT8TFV2"
      },
      "source": [
        "detailrealistic : https://civitai.com/api/download/models/329476\n",
        "\n",
        "ðŸŽ†SDXL FaeTasticðŸŽ† : https://civitai.com/api/download/models/291443\n",
        "\n",
        "MGä¸¨ : https://civitai.com/images/1126194?postId=296259\n",
        "\n",
        "logo : https://civitai.com/api/download/models/177492\n",
        "\n",
        "BusinessDesign sdxl1.5 : https://civitai.com/api/download/models/126150\n",
        "\n",
        "Bdicon sdxl 1.5 : https://civitai.com/models/100056/bdicon?modelVersionId=107090\n",
        "\n",
        "jugger8 : https://civitai.com/api/download/models/288982\n",
        "\n",
        "realisticFantasyMix :https://civitai.com/api/download/models/150243"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6PnI2whWXkm"
      },
      "source": [
        "!python entry_with_update.py --share --always-high-vram --preset detailRealistic4S"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu7IeYfjCZhs"
      },
      "source": [
        "1girl, masterpiece, best quality, analogue photo of young girl, looking at viewer, long hair, hoodie, extremely beautiful detailed face, medium breasts, (cute face, temptations look), head shot, outdoor background, high key lighting, eye level, (vignette photography), (professional photo, balanced photo, balanced exposure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9OdtWf0XD9W"
      },
      "source": [
        "a forest of semiconductor elements on a pcb with a large lake in the middle, <lora:xinpian:0.8>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icWKvTMG9FhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca157fb5-04eb-4e93-e952-e81ce26a1074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygit2==1.12.2\n",
            "  Downloading pygit2-1.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pygit2==1.12.2) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.9.1->pygit2==1.12.2) (2.22)\n",
            "Installing collected packages: pygit2\n",
            "Successfully installed pygit2-1.12.2\n",
            "/content\n",
            "Cloning into 'FL'...\n",
            "remote: Enumerating objects: 6027, done.\u001b[K\n",
            "remote: Counting objects: 100% (225/225), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 6027 (delta 159), reused 177 (delta 125), pack-reused 5802\u001b[K\n",
            "Receiving objects: 100% (6027/6027), 32.14 MiB | 30.00 MiB/s, done.\n",
            "Resolving deltas: 100% (3675/3675), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.12.2\n",
        "%cd /content\n",
        "!git clone https://github.com/fawzia86/FL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwIAfW6SeAoK",
        "outputId": "ca8c0e80-7ed6-46ad-a74e-923ea1c8d7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Done success\n",
            "Skipping download as no valid Type or DirectLink_URL provided.\n"
          ]
        }
      ],
      "source": [
        "#@markdown #STEP 1: Perlengkapan Models Downloader\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "import requests\n",
        "from urllib.parse import unquote\n",
        "\n",
        "def download_model(Type, DirectLink_URL):\n",
        "    if Type == \"None\" or not DirectLink_URL:\n",
        "        print(\"Skipping download as no valid Type or DirectLink_URL provided.\")\n",
        "        return\n",
        "\n",
        "    output_path = \"/content/FL/models/\"\n",
        "\n",
        "    if Type == \"Checkpoint\":\n",
        "        output_path += \"checkpoints/\"\n",
        "    elif Type == \"LoRA\":\n",
        "        output_path += \"loras/\"\n",
        "    elif Type == \"Textual Inversion\":\n",
        "        output_path += \"embeddings/\"\n",
        "    else:\n",
        "        print(\"Invalid type specified.\")\n",
        "        return\n",
        "\n",
        "    # Create the directories if they don't exist\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    urls = [url.strip() for url in DirectLink_URL.split(\",\")]\n",
        "\n",
        "    for url in urls:\n",
        "        response = requests.get(url, stream=True)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            content_disposition = response.headers.get('content-disposition')\n",
        "            if content_disposition:\n",
        "                filename = unquote(content_disposition.split('filename=')[1])\n",
        "            else:\n",
        "                filename = unquote(url.split(\"/\")[-1])  # Extracting the filename from the URL\n",
        "\n",
        "            # Remove double quotes and semicolons from the filename\n",
        "            filename = filename.replace('\"', '').replace(';', '')\n",
        "\n",
        "            filename = os.path.join(output_path, filename)  # Modify the filename to include the output path\n",
        "\n",
        "            if not os.path.exists(filename):\n",
        "                print(\"Downloading file:\", filename)\n",
        "                chunk_size = 5242880  # 5 MB\n",
        "                with open(filename, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "                print(\"File downloaded successfully.\")\n",
        "            else:\n",
        "                print(\"File already exists:\", filename)\n",
        "        else:\n",
        "            print(\"Failed to download the file:\", url)\n",
        "\n",
        "    # Clear the output to keep the notebook clean\n",
        "    clear_output()\n",
        "\n",
        "    # Print the success message\n",
        "    print(\"âœ… Done\", \"success\")\n",
        "\n",
        "# Call the function with the first set of parameters\n",
        "Type1 = \"Checkpoint\"  # @param [\"Checkpoint\", \"LoRA\", \"Textual Inversion\"]\n",
        "DirectLink_URL1 = \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/juggernautXL_v8Rundiffusion.safetensors\"  # @param {'type': 'string'}\n",
        "download_model(Type1, DirectLink_URL1)\n",
        "\n",
        "# Call the function with the second set of parameters\n",
        "Type2 = \"None\"  # @param [\"None\", \"Checkpoint\", \"LoRA\", \"Textual Inversion\"]\n",
        "DirectLink_URL2 = \"\"  # @param {'type': 'string'}\n",
        "download_model(Type2, DirectLink_URL2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw7FQ1_Rd9Sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec3d33d-dcba-43fe-cd8f-deb92a763929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FL\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram', '--preset', 'JGxl']\n",
            "Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Fooocus version: 2.3.0\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "Loaded preset: /content/FL/presets/JGxl.json\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/FL/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 4.07MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/FL/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 4.19MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xl-to-v1_interposer-v3.1.safetensors\" to /content/FL/models/vae_approx/xl-to-v1_interposer-v3.1.safetensors\n",
            "\n",
            "100% 6.25M/6.25M [00:00<00:00, 44.3MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/FL/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:02<00:00, 151MB/s]\n",
            "Downloading: \"https://civitai.com/api/download/models/329420\" to /content/FL/models/checkpoints/AlbedoBaseXL.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:23<00:00, 83.4MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/sdvn7Nijistylexl_v1.safetensors\" to /content/FL/models/checkpoints/SDVN7-NijiStyleXL.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:09<00:00, 100MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/unaestheticXL_Alb2.safetensors\" to /content/FL/models/embeddings/unaestheticXLv31.safetensors\n",
            "\n",
            "100% 48.5k/48.5k [00:00<00:00, 2.70MB/s]\n",
            "Downloading: \"https://civitai.com/api/download/models/20068\" to /content/FL/models/embeddings/badhandv4:1.4.safetensors\n",
            "\n",
            "100% 18.9k/18.9k [00:00<00:00, 37.2MB/s]\n",
            "Downloading: \"https://civitai.com/api/download/models/9208\" to /content/FL/models/embeddings/EasyNegative.safetensors\n",
            "\n",
            "100% 24.1k/24.1k [00:00<00:00, 43.0MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/FL/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 117MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/mjilluminate-000010.safetensors\" to /content/FL/models/loras/MJ.safetensors\n",
            "\n",
            "100% 870M/870M [00:15<00:00, 59.5MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/detailed_notrigger.safetensors\" to /content/FL/models/loras/detailed_notrigger.safetensors\n",
            "\n",
            "100% 11.7M/11.7M [00:00<00:00, 65.8MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/detailed_hands-000002.safetensors\" to /content/FL/models/loras/detailed_hands.safetensors\n",
            "\n",
            "100% 54.8M/54.8M [00:00<00:00, 62.5MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/add-detail-xl.safetensors\" to /content/FL/models/loras/dd-detail-xl.safetensors\n",
            "\n",
            "100% 218M/218M [00:02<00:00, 114MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/CoolWear.safetensors\" to /content/FL/models/loras/coolwear.safetensors\n",
            "\n",
            "100% 36.1M/36.1M [00:00<00:00, 74.4MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/xl_more_art-full_v1.safetensors\" to /content/FL/models/loras/xl_more_art-full.safetensors\n",
            "\n",
            "100% 686M/686M [00:07<00:00, 94.6MB/s]\n",
            "Downloading: \"https://huggingface.co/wfdsdfsdfwer/FL/resolve/main/DreamARTSDXL.safetensors\" to /content/FL/models/loras/DreamART Style LORA.safetensors\n",
            "\n",
            "100% 54.8M/54.8M [00:00<00:00, 113MB/s]\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "2024-04-23 04:45:27.298237: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-23 04:45:27.298300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-23 04:45:27.448591: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-23 04:45:30.226465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Refiner unloaded.\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://603cf3f25eb41d5e1f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/FL/models/checkpoints/AlbedoBaseXL.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/FL/models/checkpoints/AlbedoBaseXL.safetensors].\n",
            "Loaded LoRA [/content/FL/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/FL/models/checkpoints/AlbedoBaseXL.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "Started worker with PID 616\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://603cf3f25eb41d5e1f.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 7628442967607742881\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.60 seconds\n",
            "Base model loaded: /content/FL/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['dd-detail-xl.safetensors', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/FL/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/FL/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/FL/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Loaded LoRA [/content/FL/models/loras/dd-detail-xl.safetensors] for UNet [/content/FL/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 722 keys at weight 1.0.\n",
            "Loaded LoRA [/content/FL/models/loras/dd-detail-xl.safetensors] for CLIP [/content/FL/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 264 keys at weight 1.0.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.23 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (720, 1080)\n",
            "Preparation time: 55.20 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.26 seconds\n",
            "100% 30/30 [00:20<00:00,  1.48it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.34 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 24.18 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "100% 30/30 [00:19<00:00,  1.52it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 22.83 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 104.92 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.98 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 2878802063079551084\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding positive #5 ...\n",
            "[Fooocus] Encoding positive #6 ...\n",
            "[Fooocus] Encoding positive #7 ...\n",
            "[Fooocus] Encoding positive #8 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Encoding negative #5 ...\n",
            "[Fooocus] Encoding negative #6 ...\n",
            "[Fooocus] Encoding negative #7 ...\n",
            "[Fooocus] Encoding negative #8 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1024, 1024)\n",
            "Preparation time: 0.42 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.22 seconds\n",
            "100% 30/30 [00:26<00:00,  1.15it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 30.41 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "100% 30/30 [00:27<00:00,  1.08it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 31.64 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.89 seconds\n",
            " 30% 9/30 [00:08<00:20,  1.01it/s]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 72.34 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.93 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 5887884128998512554\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.68 seconds\n",
            "Base model loaded: /content/FL/models/checkpoints/AlbedoBaseXL.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['dd-detail-xl.safetensors', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/FL/models/checkpoints/AlbedoBaseXL.safetensors].\n",
            "Loaded LoRA [/content/FL/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/FL/models/checkpoints/AlbedoBaseXL.safetensors] with 788 keys at weight 0.1.\n",
            "Loaded LoRA [/content/FL/models/loras/dd-detail-xl.safetensors] for UNet [/content/FL/models/checkpoints/AlbedoBaseXL.safetensors] with 722 keys at weight 1.0.\n",
            "Loaded LoRA [/content/FL/models/loras/dd-detail-xl.safetensors] for CLIP [/content/FL/models/checkpoints/AlbedoBaseXL.safetensors] with 264 keys at weight 1.0.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1024, 1024)\n",
            "Preparation time: 52.26 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.55 seconds\n",
            " 90% 27/30 [00:25<00:02,  1.07it/s]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 79.10 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 7465108320899328575\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1024, 1024)\n",
            "Preparation time: 0.42 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.29 seconds\n",
            "100% 30/30 [00:27<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 31.69 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "100% 30/30 [00:26<00:00,  1.12it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 30.58 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.93 seconds\n",
            "100% 30/30 [00:26<00:00,  1.13it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 30.35 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n",
            "100% 30/30 [00:26<00:00,  1.12it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 30.47 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.93 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 1685989265200221927\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/FL/models/checkpoints/AlbedoBaseXL.safetensors].\n",
            "Loaded LoRA [/content/FL/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/FL/models/checkpoints/AlbedoBaseXL.safetensors] with 788 keys at weight 0.1.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.04 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Picture a kawaii mushroom with a round, smiling face and large, expressive eyes, its cap adorned with colorful polka dots, set against a clean white background, radiating an aura of cuteness and charm, Cartoon, digital illustration with pastel colors and soft shading, --ar 1:1 --v 5, designed, highly detailed, sharp focus, innocent\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Picture a kawaii mushroom with a round, smiling face and large, expressive eyes, its cap adorned with colorful polka dots, set against a clean white background, radiating an aura of cuteness and charm, Cartoon, digital illustration with pastel colors and soft shading, --ar 1:1 --v 5, designed, illustrious depicted, artistic, dramatic, detailed\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (720, 1080)\n",
            "Preparation time: 6.13 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.35 seconds\n",
            "100% 30/30 [00:22<00:00,  1.36it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.33 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 25.71 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            " 47% 14/30 [00:11<00:13,  1.21it/s]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 44.08 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 7434452497422075227\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.04 seconds\n",
            "Base model loaded: /content/FL/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/FL/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/FL/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/FL/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.62 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (720, 1080)\n",
            "Preparation time: 49.69 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.21 seconds\n",
            "100% 30/30 [00:20<00:00,  1.43it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 24.49 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "100% 30/30 [00:21<00:00,  1.37it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 24.81 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 99.05 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 731786613661164514\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (720, 1080)\n",
            "Preparation time: 0.36 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.29 seconds\n",
            "100% 30/30 [00:20<00:00,  1.47it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "Image generated with private log at: /content/FL/outputs/2024-04-23/log.html\n",
            "Generating and saving time: 23.96 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            " 67% 20/30 [00:15<00:07,  1.33it/s]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FL\n",
        "!python entry_with_update.py --share --always-high-vram --preset JGxl"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}